{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸŒ¼ RAGê¸°ë²•ì˜ ì´í•´ì™€ ì ìš©(3) - 2ì°¨ì‹œ(24.11.29)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "langchain_practice\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith('langchain_practice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template('{country}ì— ëŒ€í•´ 300ì ë‚´ì™¸ë¡œ ìš”ì•½í•´ì„œ ì„¤ëª…í•´ì¤˜')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì€ ë™ì•„ì‹œì•„ì— ìœ„ì¹˜í•œ ë‚˜ë¼ë¡œ, í•œë°˜ë„ì˜ ë‚¨ìª½ì— ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤. ìˆ˜ë„ëŠ” ì„œìš¸ì´ë©°, ê³µìš©ì–´ëŠ” í•œêµ­ì–´ì…ë‹ˆë‹¤. í•œêµ­ì€ ì—­ì‚¬ì ìœ¼ë¡œ ì‚¼êµ­ì‹œëŒ€, ê³ ë ¤, ì¡°ì„  ë“±ì˜ ì™•ì¡°ë¥¼ ê±°ì³ ì™”ìœ¼ë©°, 20ì„¸ê¸°ì—ëŠ” ì¼ì œê°•ì ê¸°ì™€ í•œêµ­ ì „ìŸì„ ê²ªì—ˆìŠµë‹ˆë‹¤. í˜„ëŒ€ í•œêµ­ì€ ë¯¼ì£¼ì£¼ì˜ ì²´ì œì˜ ê³µí™”êµ­ìœ¼ë¡œ, ê²½ì œì ìœ¼ë¡œëŠ” ë°˜ë„ì²´, ìë™ì°¨, ê°€ì „ì œí’ˆ ë“± ì²¨ë‹¨ ì‚°ì—…ì—ì„œ ì„¸ê³„ì ì¸ ê²½ìŸë ¥ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. K-íŒ, ë“œë¼ë§ˆ, ì˜í™” ë“± ë¬¸í™” ì½˜í…ì¸ ë¡œë„ êµ­ì œì ì¸ ì¸ê¸°ë¥¼ ëˆ„ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country': 'í•œêµ­'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "# ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì²­ê³¼ ì‘ë‹µ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥ -> ë™ì¼í•œ ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ê²°ê³¼ë¥¼ ì¬ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì€ ë™ì•„ì‹œì•„ì— ìœ„ì¹˜í•œ êµ­ê°€ë¡œ, í•œë°˜ë„ì˜ ë‚¨ìª½ì— ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤. ê³µì‹ ëª…ì¹­ì€ ëŒ€í•œë¯¼êµ­ì´ë©°, ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤. í•œêµ­ì€ ë°˜ë„ ì§€í˜•ìœ¼ë¡œ, ë¶ìª½ìœ¼ë¡œëŠ” ë¶í•œê³¼ êµ­ê²½ì„ ì ‘í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë¬¸í™”ì ìœ¼ë¡œëŠ” í•œê¸€, í•œì‹, í•œë¥˜ ë“± ë…ìì ì¸ ë¬¸í™”ë¥¼ ë°œì „ì‹œì¼°ìœ¼ë©°, ê²½ì œì ìœ¼ë¡œëŠ” IT, ìë™ì°¨, ì¡°ì„ ì—… ë“± ì—¬ëŸ¬ ì‚°ì—…ì—ì„œ ì„¸ê³„ì ì¸ ê²½ìŸë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì •ì¹˜ ì²´ì œëŠ” ë¯¼ì£¼ê³µí™”êµ­ì´ë©°, ì‚¬íšŒì ìœ¼ë¡œëŠ” êµìœ¡ì—´ì´ ë†’ê³  ë¹ ë¥¸ ê¸°ìˆ  ë°œì „ì„ ì´ë£¨ì–´ ì™”ìŠµë‹ˆë‹¤.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 5.35 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country': 'í•œêµ­'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('cache'):\n",
    "    os.makedirs('cache')  # ìºì‹œ í´ë” ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(SQLiteCache(database_path='cache/llm_cache.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºë‚˜ë‹¤ëŠ” ë¶ì•„ë©”ë¦¬ì¹´ ëŒ€ë¥™ì˜ ë¶ìª½ì— ìœ„ì¹˜í•œ êµ­ê°€ë¡œ, ì„¸ê³„ì—ì„œ ë‘ ë²ˆì§¸ë¡œ í° ë©´ì ì„ ìë‘í•©ë‹ˆë‹¤. ìˆ˜ë„ëŠ” ì˜¤íƒ€ì™€ì´ë©°, ì£¼ìš” ë„ì‹œë¡œëŠ” í† ë¡ í† , ë°´ì¿ ë²„, ëª¬íŠ¸ë¦¬ì˜¬ ë“±ì´ ìˆìŠµë‹ˆë‹¤. ê³µìš©ì–´ëŠ” ì˜ì–´ì™€ í”„ë‘ìŠ¤ì–´ì…ë‹ˆë‹¤. í’ë¶€í•œ ìì—° ìì›ê³¼ ë‹¤ì–‘í•œ ë¬¸í™”ê°€ íŠ¹ì§•ì´ë©°, ë‹¤ë¬¸í™”ì£¼ì˜ë¥¼ ì¤‘ì‹œí•©ë‹ˆë‹¤. ì •ì¹˜ ì²´ì œëŠ” ì…í—Œêµ°ì£¼ì œì™€ ì˜ì› ë‚´ê°ì œë¥¼ ì±„íƒí•˜ê³  ìˆìœ¼ë©°, ì—˜ë¦¬ìë² ìŠ¤ 2ì„¸ ì—¬ì™•ì´ êµ­ê°€ ì›ìˆ˜ë¡œ ìˆì—ˆìœ¼ë‚˜ í˜„ì¬ëŠ” ì°°ìŠ¤ 3ì„¸ê°€ ì™•ìœ„ì— ìˆìŠµë‹ˆë‹¤. ê²½ì œëŠ” ì„œë¹„ìŠ¤ì—…, ìì› ì‚°ì—…, ì œì¡°ì—… ë“±ì´ ì£¼ë¥¼ ì´ë£¨ë©°, ë†’ì€ ì‚¶ì˜ ì§ˆê³¼ êµìœ¡ ìˆ˜ì¤€ìœ¼ë¡œ ì˜ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country': 'ìºë‚˜ë‹¤'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºë‚˜ë‹¤ëŠ” ë¶ì•„ë©”ë¦¬ì¹´ ëŒ€ë¥™ì˜ ë¶ìª½ì— ìœ„ì¹˜í•œ êµ­ê°€ë¡œ, ì„¸ê³„ì—ì„œ ë‘ ë²ˆì§¸ë¡œ í° ë©´ì ì„ ìë‘í•©ë‹ˆë‹¤. ìˆ˜ë„ëŠ” ì˜¤íƒ€ì™€ì´ë©°, ì£¼ìš” ë„ì‹œë¡œëŠ” í† ë¡ í† , ë°´ì¿ ë²„, ëª¬íŠ¸ë¦¬ì˜¬ ë“±ì´ ìˆìŠµë‹ˆë‹¤. ê³µìš©ì–´ëŠ” ì˜ì–´ì™€ í”„ë‘ìŠ¤ì–´ì…ë‹ˆë‹¤. í’ë¶€í•œ ìì—° ìì›ê³¼ ë‹¤ì–‘í•œ ë¬¸í™”ê°€ íŠ¹ì§•ì´ë©°, ë‹¤ë¬¸í™”ì£¼ì˜ë¥¼ ì¤‘ì‹œí•©ë‹ˆë‹¤. ì •ì¹˜ ì²´ì œëŠ” ì…í—Œêµ°ì£¼ì œì™€ ì˜ì› ë‚´ê°ì œë¥¼ ì±„íƒí•˜ê³  ìˆìœ¼ë©°, ì—˜ë¦¬ìë² ìŠ¤ 2ì„¸ ì—¬ì™•ì´ êµ­ê°€ ì›ìˆ˜ë¡œ ìˆì—ˆìœ¼ë‚˜ í˜„ì¬ëŠ” ì°°ìŠ¤ 3ì„¸ê°€ ì™•ìœ„ì— ìˆìŠµë‹ˆë‹¤. ê²½ì œëŠ” ì„œë¹„ìŠ¤ì—…, ìì› ì‚°ì—…, ì œì¡°ì—… ë“±ì´ ì£¼ë¥¼ ì´ë£¨ë©°, ë†’ì€ ì‚¶ì˜ ì§ˆê³¼ êµìœ¡ ìˆ˜ì¤€ìœ¼ë¡œ ì˜ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 5.92 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country': 'ìºë‚˜ë‹¤'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜êµ­ì€ ìœ ëŸ½ ë¶ì„œë¶€ì— ìœ„ì¹˜í•œ ì„¬ë‚˜ë¼ë¡œ, ì‰ê¸€ëœë“œ, ìŠ¤ì½”í‹€ëœë“œ, ì›¨ì¼ìŠ¤, ë¶ì•„ì¼ëœë“œë¡œ êµ¬ì„±ëœ ì—°í•© ì™•êµ­ì…ë‹ˆë‹¤. ìˆ˜ë„ëŠ” ëŸ°ë˜ì´ë©°, ì…í—Œ êµ°ì£¼ì œì™€ ì˜íšŒ ë¯¼ì£¼ì£¼ì˜ë¥¼ ì±„íƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜êµ­ì€ ì‚°ì—…í˜ëª…ì˜ ë°œìƒì§€ë¡œ, ì„¸ê³„ ê²½ì œì™€ ë¬¸í™”ì— í° ì˜í–¥ì„ ë¯¸ì³¤ìŠµë‹ˆë‹¤. ì˜ì–´ì˜ ë³¸ê³ ì¥ì´ë©°, ìœ ëª…í•œ ë¬¸í™”ì  ì•„ì´ì½˜ìœ¼ë¡œ ì…°ìµìŠ¤í”¼ì–´, ë¹„í‹€ì¦ˆ ë“±ì´ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ëŠ” ë‹¤ì–‘í•œ ì¸ì¢…ê³¼ ë¬¸í™”ë¥¼ í¬ìš©í•˜ëŠ” ë‹¤ë¬¸í™” ì‚¬íšŒë¡œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 3.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country': 'ì˜êµ­'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'cache/llm_cache.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables [('full_llm_cache',), ('full_md5_llm_cache',)]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print('Tables', tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cache contents: \n",
      "('[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"\\\\uce90\\\\ub098\\\\ub2e4\\\\uc5d0 \\\\ub300\\\\ud574 300\\\\uc790 \\\\ub0b4\\\\uc678\\\\ub85c \\\\uc694\\\\uc57d\\\\ud574\\\\uc11c \\\\uc124\\\\uba85\\\\ud574\\\\uc918\", \"type\": \"human\"}}]', '{\"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"max_retries\": 2, \"model_name\": \"gpt-4o\", \"n\": 1, \"openai_api_key\": {\"id\": [\"OPENAI_API_KEY\"], \"lc\": 1, \"type\": \"secret\"}, \"temperature\": 0.7}, \"lc\": 1, \"name\": \"ChatOpenAI\", \"type\": \"constructor\"}---[(\\'stop\\', None)]', 0, '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"output\", \"ChatGeneration\"], \"kwargs\": {\"text\": \"\\\\uce90\\\\ub098\\\\ub2e4\\\\ub294 \\\\ubd81\\\\uc544\\\\uba54\\\\ub9ac\\\\uce74 \\\\ub300\\\\ub959\\\\uc758 \\\\ubd81\\\\ucabd\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\uad6d\\\\uac00\\\\ub85c, \\\\uc138\\\\uacc4\\\\uc5d0\\\\uc11c \\\\ub450 \\\\ubc88\\\\uc9f8\\\\ub85c \\\\ud070 \\\\uba74\\\\uc801\\\\uc744 \\\\uc790\\\\ub791\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc218\\\\ub3c4\\\\ub294 \\\\uc624\\\\ud0c0\\\\uc640\\\\uc774\\\\uba70, \\\\uc8fc\\\\uc694 \\\\ub3c4\\\\uc2dc\\\\ub85c\\\\ub294 \\\\ud1a0\\\\ub860\\\\ud1a0, \\\\ubc34\\\\ucfe0\\\\ubc84, \\\\ubaac\\\\ud2b8\\\\ub9ac\\\\uc62c \\\\ub4f1\\\\uc774 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uacf5\\\\uc6a9\\\\uc5b4\\\\ub294 \\\\uc601\\\\uc5b4\\\\uc640 \\\\ud504\\\\ub791\\\\uc2a4\\\\uc5b4\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\ud48d\\\\ubd80\\\\ud55c \\\\uc790\\\\uc5f0 \\\\uc790\\\\uc6d0\\\\uacfc \\\\ub2e4\\\\uc591\\\\ud55c \\\\ubb38\\\\ud654\\\\uac00 \\\\ud2b9\\\\uc9d5\\\\uc774\\\\uba70, \\\\ub2e4\\\\ubb38\\\\ud654\\\\uc8fc\\\\uc758\\\\ub97c \\\\uc911\\\\uc2dc\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc815\\\\uce58 \\\\uccb4\\\\uc81c\\\\ub294 \\\\uc785\\\\ud5cc\\\\uad70\\\\uc8fc\\\\uc81c\\\\uc640 \\\\uc758\\\\uc6d0 \\\\ub0b4\\\\uac01\\\\uc81c\\\\ub97c \\\\ucc44\\\\ud0dd\\\\ud558\\\\uace0 \\\\uc788\\\\uc73c\\\\uba70, \\\\uc5d8\\\\ub9ac\\\\uc790\\\\ubca0\\\\uc2a4 2\\\\uc138 \\\\uc5ec\\\\uc655\\\\uc774 \\\\uad6d\\\\uac00 \\\\uc6d0\\\\uc218\\\\ub85c \\\\uc788\\\\uc5c8\\\\uc73c\\\\ub098 \\\\ud604\\\\uc7ac\\\\ub294 \\\\ucc30\\\\uc2a4 3\\\\uc138\\\\uac00 \\\\uc655\\\\uc704\\\\uc5d0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uacbd\\\\uc81c\\\\ub294 \\\\uc11c\\\\ube44\\\\uc2a4\\\\uc5c5, \\\\uc790\\\\uc6d0 \\\\uc0b0\\\\uc5c5, \\\\uc81c\\\\uc870\\\\uc5c5 \\\\ub4f1\\\\uc774 \\\\uc8fc\\\\ub97c \\\\uc774\\\\ub8e8\\\\uba70, \\\\ub192\\\\uc740 \\\\uc0b6\\\\uc758 \\\\uc9c8\\\\uacfc \\\\uad50\\\\uc721 \\\\uc218\\\\uc900\\\\uc73c\\\\ub85c \\\\uc798 \\\\uc54c\\\\ub824\\\\uc838 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4.\", \"generation_info\": {\"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ChatGeneration\", \"message\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"AIMessage\"], \"kwargs\": {\"content\": \"\\\\uce90\\\\ub098\\\\ub2e4\\\\ub294 \\\\ubd81\\\\uc544\\\\uba54\\\\ub9ac\\\\uce74 \\\\ub300\\\\ub959\\\\uc758 \\\\ubd81\\\\ucabd\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\uad6d\\\\uac00\\\\ub85c, \\\\uc138\\\\uacc4\\\\uc5d0\\\\uc11c \\\\ub450 \\\\ubc88\\\\uc9f8\\\\ub85c \\\\ud070 \\\\uba74\\\\uc801\\\\uc744 \\\\uc790\\\\ub791\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc218\\\\ub3c4\\\\ub294 \\\\uc624\\\\ud0c0\\\\uc640\\\\uc774\\\\uba70, \\\\uc8fc\\\\uc694 \\\\ub3c4\\\\uc2dc\\\\ub85c\\\\ub294 \\\\ud1a0\\\\ub860\\\\ud1a0, \\\\ubc34\\\\ucfe0\\\\ubc84, \\\\ubaac\\\\ud2b8\\\\ub9ac\\\\uc62c \\\\ub4f1\\\\uc774 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uacf5\\\\uc6a9\\\\uc5b4\\\\ub294 \\\\uc601\\\\uc5b4\\\\uc640 \\\\ud504\\\\ub791\\\\uc2a4\\\\uc5b4\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\ud48d\\\\ubd80\\\\ud55c \\\\uc790\\\\uc5f0 \\\\uc790\\\\uc6d0\\\\uacfc \\\\ub2e4\\\\uc591\\\\ud55c \\\\ubb38\\\\ud654\\\\uac00 \\\\ud2b9\\\\uc9d5\\\\uc774\\\\uba70, \\\\ub2e4\\\\ubb38\\\\ud654\\\\uc8fc\\\\uc758\\\\ub97c \\\\uc911\\\\uc2dc\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc815\\\\uce58 \\\\uccb4\\\\uc81c\\\\ub294 \\\\uc785\\\\ud5cc\\\\uad70\\\\uc8fc\\\\uc81c\\\\uc640 \\\\uc758\\\\uc6d0 \\\\ub0b4\\\\uac01\\\\uc81c\\\\ub97c \\\\ucc44\\\\ud0dd\\\\ud558\\\\uace0 \\\\uc788\\\\uc73c\\\\uba70, \\\\uc5d8\\\\ub9ac\\\\uc790\\\\ubca0\\\\uc2a4 2\\\\uc138 \\\\uc5ec\\\\uc655\\\\uc774 \\\\uad6d\\\\uac00 \\\\uc6d0\\\\uc218\\\\ub85c \\\\uc788\\\\uc5c8\\\\uc73c\\\\ub098 \\\\ud604\\\\uc7ac\\\\ub294 \\\\ucc30\\\\uc2a4 3\\\\uc138\\\\uac00 \\\\uc655\\\\uc704\\\\uc5d0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uacbd\\\\uc81c\\\\ub294 \\\\uc11c\\\\ube44\\\\uc2a4\\\\uc5c5, \\\\uc790\\\\uc6d0 \\\\uc0b0\\\\uc5c5, \\\\uc81c\\\\uc870\\\\uc5c5 \\\\ub4f1\\\\uc774 \\\\uc8fc\\\\ub97c \\\\uc774\\\\ub8e8\\\\uba70, \\\\ub192\\\\uc740 \\\\uc0b6\\\\uc758 \\\\uc9c8\\\\uacfc \\\\uad50\\\\uc721 \\\\uc218\\\\uc900\\\\uc73c\\\\ub85c \\\\uc798 \\\\uc54c\\\\ub824\\\\uc838 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4.\", \"additional_kwargs\": {\"refusal\": null}, \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 176, \"prompt_tokens\": 23, \"total_tokens\": 199, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}, \"model_name\": \"gpt-4o-2024-08-06\", \"system_fingerprint\": \"fp_7f6be3efb0\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"id\": \"run-58f6b2f4-60c7-4603-8aec-51de8a561037-0\", \"usage_metadata\": {\"input_tokens\": 23, \"output_tokens\": 176, \"total_tokens\": 199, \"input_token_details\": {\"audio\": 0, \"cache_read\": 0}, \"output_token_details\": {\"audio\": 0, \"reasoning\": 0}}, \"tool_calls\": [], \"invalid_tool_calls\": []}}}}')\n",
      "('[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"\\\\ud55c\\\\uad6d\\\\uc5d0 \\\\ub300\\\\ud574 300\\\\uc790 \\\\ub0b4\\\\uc678\\\\ub85c \\\\uc694\\\\uc57d\\\\ud574\\\\uc11c \\\\uc124\\\\uba85\\\\ud574\\\\uc918\", \"type\": \"human\"}}]', '{\"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"max_retries\": 2, \"model_name\": \"gpt-4o\", \"n\": 1, \"openai_api_key\": {\"id\": [\"OPENAI_API_KEY\"], \"lc\": 1, \"type\": \"secret\"}, \"temperature\": 0.7}, \"lc\": 1, \"name\": \"ChatOpenAI\", \"type\": \"constructor\"}---[(\\'stop\\', None)]', 0, '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"output\", \"ChatGeneration\"], \"kwargs\": {\"text\": \"\\\\ud55c\\\\uad6d\\\\uc740 \\\\ub3d9\\\\uc544\\\\uc2dc\\\\uc544\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\ub098\\\\ub77c\\\\ub85c, \\\\ud55c\\\\ubc18\\\\ub3c4\\\\uc758 \\\\ub0a8\\\\ucabd\\\\uc5d0 \\\\uc790\\\\ub9ac\\\\uc7a1\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uc218\\\\ub3c4\\\\ub294 \\\\uc11c\\\\uc6b8\\\\uc774\\\\uba70, \\\\uacf5\\\\uc6a9\\\\uc5b4\\\\ub294 \\\\ud55c\\\\uad6d\\\\uc5b4\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\ud55c\\\\uad6d\\\\uc740 \\\\uc5ed\\\\uc0ac\\\\uc801\\\\uc73c\\\\ub85c \\\\uc0bc\\\\uad6d\\\\uc2dc\\\\ub300, \\\\uace0\\\\ub824, \\\\uc870\\\\uc120 \\\\ub4f1\\\\uc758 \\\\uc655\\\\uc870\\\\ub97c \\\\uac70\\\\uccd0 \\\\uc654\\\\uc73c\\\\uba70, 20\\\\uc138\\\\uae30\\\\uc5d0\\\\ub294 \\\\uc77c\\\\uc81c\\\\uac15\\\\uc810\\\\uae30\\\\uc640 \\\\ud55c\\\\uad6d \\\\uc804\\\\uc7c1\\\\uc744 \\\\uacaa\\\\uc5c8\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\ud604\\\\ub300 \\\\ud55c\\\\uad6d\\\\uc740 \\\\ubbfc\\\\uc8fc\\\\uc8fc\\\\uc758 \\\\uccb4\\\\uc81c\\\\uc758 \\\\uacf5\\\\ud654\\\\uad6d\\\\uc73c\\\\ub85c, \\\\uacbd\\\\uc81c\\\\uc801\\\\uc73c\\\\ub85c\\\\ub294 \\\\ubc18\\\\ub3c4\\\\uccb4, \\\\uc790\\\\ub3d9\\\\ucc28, \\\\uac00\\\\uc804\\\\uc81c\\\\ud488 \\\\ub4f1 \\\\ucca8\\\\ub2e8 \\\\uc0b0\\\\uc5c5\\\\uc5d0\\\\uc11c \\\\uc138\\\\uacc4\\\\uc801\\\\uc778 \\\\uacbd\\\\uc7c1\\\\ub825\\\\uc744 \\\\uac16\\\\ucd94\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. K-\\\\ud31d, \\\\ub4dc\\\\ub77c\\\\ub9c8, \\\\uc601\\\\ud654 \\\\ub4f1 \\\\ubb38\\\\ud654 \\\\ucf58\\\\ud150\\\\uce20\\\\ub85c\\\\ub3c4 \\\\uad6d\\\\uc81c\\\\uc801\\\\uc778 \\\\uc778\\\\uae30\\\\ub97c \\\\ub204\\\\ub9ac\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4.\", \"generation_info\": {\"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ChatGeneration\", \"message\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"AIMessage\"], \"kwargs\": {\"content\": \"\\\\ud55c\\\\uad6d\\\\uc740 \\\\ub3d9\\\\uc544\\\\uc2dc\\\\uc544\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\ub098\\\\ub77c\\\\ub85c, \\\\ud55c\\\\ubc18\\\\ub3c4\\\\uc758 \\\\ub0a8\\\\ucabd\\\\uc5d0 \\\\uc790\\\\ub9ac\\\\uc7a1\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uc218\\\\ub3c4\\\\ub294 \\\\uc11c\\\\uc6b8\\\\uc774\\\\uba70, \\\\uacf5\\\\uc6a9\\\\uc5b4\\\\ub294 \\\\ud55c\\\\uad6d\\\\uc5b4\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\ud55c\\\\uad6d\\\\uc740 \\\\uc5ed\\\\uc0ac\\\\uc801\\\\uc73c\\\\ub85c \\\\uc0bc\\\\uad6d\\\\uc2dc\\\\ub300, \\\\uace0\\\\ub824, \\\\uc870\\\\uc120 \\\\ub4f1\\\\uc758 \\\\uc655\\\\uc870\\\\ub97c \\\\uac70\\\\uccd0 \\\\uc654\\\\uc73c\\\\uba70, 20\\\\uc138\\\\uae30\\\\uc5d0\\\\ub294 \\\\uc77c\\\\uc81c\\\\uac15\\\\uc810\\\\uae30\\\\uc640 \\\\ud55c\\\\uad6d \\\\uc804\\\\uc7c1\\\\uc744 \\\\uacaa\\\\uc5c8\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\ud604\\\\ub300 \\\\ud55c\\\\uad6d\\\\uc740 \\\\ubbfc\\\\uc8fc\\\\uc8fc\\\\uc758 \\\\uccb4\\\\uc81c\\\\uc758 \\\\uacf5\\\\ud654\\\\uad6d\\\\uc73c\\\\ub85c, \\\\uacbd\\\\uc81c\\\\uc801\\\\uc73c\\\\ub85c\\\\ub294 \\\\ubc18\\\\ub3c4\\\\uccb4, \\\\uc790\\\\ub3d9\\\\ucc28, \\\\uac00\\\\uc804\\\\uc81c\\\\ud488 \\\\ub4f1 \\\\ucca8\\\\ub2e8 \\\\uc0b0\\\\uc5c5\\\\uc5d0\\\\uc11c \\\\uc138\\\\uacc4\\\\uc801\\\\uc778 \\\\uacbd\\\\uc7c1\\\\ub825\\\\uc744 \\\\uac16\\\\ucd94\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. K-\\\\ud31d, \\\\ub4dc\\\\ub77c\\\\ub9c8, \\\\uc601\\\\ud654 \\\\ub4f1 \\\\ubb38\\\\ud654 \\\\ucf58\\\\ud150\\\\uce20\\\\ub85c\\\\ub3c4 \\\\uad6d\\\\uc81c\\\\uc801\\\\uc778 \\\\uc778\\\\uae30\\\\ub97c \\\\ub204\\\\ub9ac\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4.\", \"additional_kwargs\": {\"refusal\": null}, \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 139, \"prompt_tokens\": 22, \"total_tokens\": 161, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}, \"model_name\": \"gpt-4o-2024-08-06\", \"system_fingerprint\": \"fp_7f6be3efb0\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"id\": \"run-006c69fa-6fae-461c-97fb-5181dd7c723a-0\", \"usage_metadata\": {\"input_tokens\": 22, \"output_tokens\": 139, \"total_tokens\": 161, \"input_token_details\": {\"audio\": 0, \"cache_read\": 0}, \"output_token_details\": {\"audio\": 0, \"reasoning\": 0}}, \"tool_calls\": [], \"invalid_tool_calls\": []}}}}')\n",
      "('[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"\\\\uc601\\\\uad6d\\\\uc5d0 \\\\ub300\\\\ud574 300\\\\uc790 \\\\ub0b4\\\\uc678\\\\ub85c \\\\uc694\\\\uc57d\\\\ud574\\\\uc11c \\\\uc124\\\\uba85\\\\ud574\\\\uc918\", \"type\": \"human\"}}]', '{\"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"max_retries\": 2, \"model_name\": \"gpt-4o\", \"n\": 1, \"openai_api_key\": {\"id\": [\"OPENAI_API_KEY\"], \"lc\": 1, \"type\": \"secret\"}, \"temperature\": 0.7}, \"lc\": 1, \"name\": \"ChatOpenAI\", \"type\": \"constructor\"}---[(\\'stop\\', None)]', 0, '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"output\", \"ChatGeneration\"], \"kwargs\": {\"text\": \"\\\\uc601\\\\uad6d\\\\uc740 \\\\uc720\\\\ub7fd \\\\ubd81\\\\uc11c\\\\ubd80\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\uc12c\\\\ub098\\\\ub77c\\\\ub85c, \\\\uc789\\\\uae00\\\\ub79c\\\\ub4dc, \\\\uc2a4\\\\ucf54\\\\ud2c0\\\\ub79c\\\\ub4dc, \\\\uc6e8\\\\uc77c\\\\uc2a4, \\\\ubd81\\\\uc544\\\\uc77c\\\\ub79c\\\\ub4dc\\\\ub85c \\\\uad6c\\\\uc131\\\\ub41c \\\\uc5f0\\\\ud569 \\\\uc655\\\\uad6d\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc218\\\\ub3c4\\\\ub294 \\\\ub7f0\\\\ub358\\\\uc774\\\\uba70, \\\\uc785\\\\ud5cc \\\\uad70\\\\uc8fc\\\\uc81c\\\\uc640 \\\\uc758\\\\ud68c \\\\ubbfc\\\\uc8fc\\\\uc8fc\\\\uc758\\\\ub97c \\\\ucc44\\\\ud0dd\\\\ud558\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uc601\\\\uad6d\\\\uc740 \\\\uc0b0\\\\uc5c5\\\\ud601\\\\uba85\\\\uc758 \\\\ubc1c\\\\uc0c1\\\\uc9c0\\\\ub85c, \\\\uc138\\\\uacc4 \\\\uacbd\\\\uc81c\\\\uc640 \\\\ubb38\\\\ud654\\\\uc5d0 \\\\ud070 \\\\uc601\\\\ud5a5\\\\uc744 \\\\ubbf8\\\\ucce4\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uc601\\\\uc5b4\\\\uc758 \\\\ubcf8\\\\uace0\\\\uc7a5\\\\uc774\\\\uba70, \\\\uc720\\\\uba85\\\\ud55c \\\\ubb38\\\\ud654\\\\uc801 \\\\uc544\\\\uc774\\\\ucf58\\\\uc73c\\\\ub85c \\\\uc170\\\\uc775\\\\uc2a4\\\\ud53c\\\\uc5b4, \\\\ube44\\\\ud2c0\\\\uc988 \\\\ub4f1\\\\uc774 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\ud604\\\\uc7ac\\\\ub294 \\\\ub2e4\\\\uc591\\\\ud55c \\\\uc778\\\\uc885\\\\uacfc \\\\ubb38\\\\ud654\\\\ub97c \\\\ud3ec\\\\uc6a9\\\\ud558\\\\ub294 \\\\ub2e4\\\\ubb38\\\\ud654 \\\\uc0ac\\\\ud68c\\\\ub85c \\\\ubc1c\\\\uc804\\\\ud558\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4.\", \"generation_info\": {\"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ChatGeneration\", \"message\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"AIMessage\"], \"kwargs\": {\"content\": \"\\\\uc601\\\\uad6d\\\\uc740 \\\\uc720\\\\ub7fd \\\\ubd81\\\\uc11c\\\\ubd80\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\uc12c\\\\ub098\\\\ub77c\\\\ub85c, \\\\uc789\\\\uae00\\\\ub79c\\\\ub4dc, \\\\uc2a4\\\\ucf54\\\\ud2c0\\\\ub79c\\\\ub4dc, \\\\uc6e8\\\\uc77c\\\\uc2a4, \\\\ubd81\\\\uc544\\\\uc77c\\\\ub79c\\\\ub4dc\\\\ub85c \\\\uad6c\\\\uc131\\\\ub41c \\\\uc5f0\\\\ud569 \\\\uc655\\\\uad6d\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc218\\\\ub3c4\\\\ub294 \\\\ub7f0\\\\ub358\\\\uc774\\\\uba70, \\\\uc785\\\\ud5cc \\\\uad70\\\\uc8fc\\\\uc81c\\\\uc640 \\\\uc758\\\\ud68c \\\\ubbfc\\\\uc8fc\\\\uc8fc\\\\uc758\\\\ub97c \\\\ucc44\\\\ud0dd\\\\ud558\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uc601\\\\uad6d\\\\uc740 \\\\uc0b0\\\\uc5c5\\\\ud601\\\\uba85\\\\uc758 \\\\ubc1c\\\\uc0c1\\\\uc9c0\\\\ub85c, \\\\uc138\\\\uacc4 \\\\uacbd\\\\uc81c\\\\uc640 \\\\ubb38\\\\ud654\\\\uc5d0 \\\\ud070 \\\\uc601\\\\ud5a5\\\\uc744 \\\\ubbf8\\\\ucce4\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uc601\\\\uc5b4\\\\uc758 \\\\ubcf8\\\\uace0\\\\uc7a5\\\\uc774\\\\uba70, \\\\uc720\\\\uba85\\\\ud55c \\\\ubb38\\\\ud654\\\\uc801 \\\\uc544\\\\uc774\\\\ucf58\\\\uc73c\\\\ub85c \\\\uc170\\\\uc775\\\\uc2a4\\\\ud53c\\\\uc5b4, \\\\ube44\\\\ud2c0\\\\uc988 \\\\ub4f1\\\\uc774 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\ud604\\\\uc7ac\\\\ub294 \\\\ub2e4\\\\uc591\\\\ud55c \\\\uc778\\\\uc885\\\\uacfc \\\\ubb38\\\\ud654\\\\ub97c \\\\ud3ec\\\\uc6a9\\\\ud558\\\\ub294 \\\\ub2e4\\\\ubb38\\\\ud654 \\\\uc0ac\\\\ud68c\\\\ub85c \\\\ubc1c\\\\uc804\\\\ud558\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4.\", \"additional_kwargs\": {\"refusal\": null}, \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 135, \"prompt_tokens\": 23, \"total_tokens\": 158, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}, \"model_name\": \"gpt-4o-2024-08-06\", \"system_fingerprint\": \"fp_7f6be3efb0\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"id\": \"run-64a80bb1-c5c8-4401-966c-fdc408ad6de9-0\", \"usage_metadata\": {\"input_tokens\": 23, \"output_tokens\": 135, \"total_tokens\": 158, \"input_token_details\": {\"audio\": 0, \"cache_read\": 0}, \"output_token_details\": {\"audio\": 0, \"reasoning\": 0}}, \"tool_calls\": [], \"invalid_tool_calls\": []}}}}')\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT * FROM full_llm_cache;\")\n",
    "rows = cursor.fetchall()\n",
    "print('\\ncache contents: ')\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 24\n",
      "\tPrompt Tokens: 16\n",
      "\tCompletion Tokens: 8\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00012000000000000002\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 800 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke('ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?')\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì‚¬ìš©ëœ í† í° ìˆ˜: 25\n",
      "í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ëœ í† í° ìˆ˜: 15\n",
      "ë‹µë³€ì— ì‚¬ìš©ëœ í† í° ìˆ˜: 10\n",
      "í˜¸ì¶œì— ì²­êµ¬ëœ ê¸ˆì•¡(USD): 0.0001375\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke('ê²¨ìš¸ì€ ì˜ì–´ë¡œ ë­ì•¼?')\n",
    "    print(f'ì´ ì‚¬ìš©ëœ í† í° ìˆ˜: {cb.total_tokens}')\n",
    "    print(f'í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ëœ í† í° ìˆ˜: {cb.prompt_tokens}')\n",
    "    print(f'ë‹µë³€ì— ì‚¬ìš©ëœ í† í° ìˆ˜: {cb.completion_tokens}')\n",
    "    print(f'í˜¸ì¶œì— ì²­êµ¬ëœ ê¸ˆì•¡(USD): {cb.total_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain-community arxiv pymupdf pypdf unstructured python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/SPRi AI Brief_11ì›”í˜¸_ì‚°ì—…ë™í–¥_F.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metadata(docs):\n",
    "    if docs:\n",
    "        print('[metadata]')\n",
    "        keys = []\n",
    "        for k in docs[0].metadata.keys():\n",
    "            keys.append(k)\n",
    "        print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source', 'page']\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  2024-11ì›”í˜¸\n",
      "20\n",
      "ì¸ë””ë“œ ì¡°ì‚¬ ê²°ê³¼, ìƒì„±AIê°€ ì¸ê°„ ê·¼ë¡œì ëŒ€ì²´í•  ê°€ëŠ¥ì„±ì€ í¬ë°•nì¸ë””ë“œê°€ 2,800ê°œ ì´ìƒì˜ ì§ë¬´ ê¸°ìˆ ì— ëŒ€í•œ ìƒì„±AIì˜ ìˆ˜í–‰ ëŠ¥ë ¥ì„ ë¶„ì„í•´ ì¸ê°„ì„ ëŒ€ì²´í•  ê°€ëŠ¥ì„±ì„ í‰ê°€í•œ ê²°ê³¼, ìƒì„±AIë¡œ ëŒ€ì²´ë  ê°€ëŠ¥ì„±ì´ â€œë§¤ìš° ë†’ì€â€ ê²ƒìœ¼ë¡œ í‰ê°€ëœ ê¸°ìˆ ì€ ì „ë¬´nìƒì„±AIì˜ ìµœëŒ€ ê°•ì ì€ ì§ë¬´ ê¸°ìˆ ê³¼ ê´€ë ¨ëœ ì´ë¡ ì  ì§€ì‹ì„ ì œê³µí•˜ëŠ” ëŠ¥ë ¥ì´ë©°, ë¬¼ë¦¬ì  ì‘ì—… ìˆ˜í–‰ì´ í•„ìš”í•œ ì§ë¬´ ê¸°ìˆ ì—ì„œëŠ” ì¸ê°„ ê·¼ë¡œìë¥¼ ëŒ€ì²´í•  ê°€ëŠ¥ì„±ì´ í¬ë°• \n",
      "KEY Contents\n",
      "Â£ìƒì„±AI, ë¬¸ì œ í•´ê²° ì—­ëŸ‰ ë° ë¬¼ë¦¬ì  ì‘ì—… ìˆ˜í–‰ ì—­ëŸ‰ì˜ ë¶€ì¡±ìœ¼ë¡œ ì¸ê°„ ê·¼ë¡œì ëŒ€ì²´ì— í•œê³„në¯¸êµ­ì˜ ì±„ìš© í”Œë«í¼ ì¸ë””ë“œ(Indeed) ì‚°í•˜ ì—°êµ¬ì†Œ í•˜ì´ì–´ë§ë©(Hiring Lab)ì´ 2024ë…„ 9ì›” 25ì¼ ë°œí‘œí•œ ì—°êµ¬ ê²°ê³¼ì— ë”°ë¥´ë©´ ìƒì„±AIê°€ ì¸ê°„ ê·¼ë¡œìë¥¼ ëŒ€ì²´í•  ê°€ëŠ¥ì„±ì€ í¬ë°•âˆ™ì¸ë””ë“œ í•˜ì´ì–´ë§ë©ì€ ì˜¤í”ˆAIì˜ GPT-4oë¡œ 2,800ê°œ ì´ìƒì˜ ê³ ìœ í•œ ì§ë¬´ ê¸°ìˆ ì— ëŒ€í•œ ìƒì„±AIì˜ ìˆ˜í–‰ ëŠ¥ë ¥ì„ ë¶„ì„í•´ ìƒì„±AIê°€ ì¸ê°„ì„ ëŒ€ì²´í•  ê°€ëŠ¥ì„±ì„ í‰ê°€âˆ™ì—°êµ¬ì§„ì€ ì˜¤í”ˆAIì˜ GPT-4oê°€ â–³ê¸°ìˆ ê³¼ ê´€ë ¨ëœ ì´ë¡ ì  ì§€ì‹ì˜ ì œê³µ ì—­ëŸ‰ â–³ê¸°ìˆ ì„ ì‚¬ìš©í•œ ë¬¸ì œ í•´ê²° ì—­ëŸ‰ â–³ê¸°ìˆ  í™œìš© ì‹œ ë¬¼ë¦¬ì  ì‘ì—…ì˜ ì¤‘ìš”ì„±ì— ê´€í•œ íŒë‹¨ ëŠ¥ë ¥ì˜ 3ê°œ ì°¨ì›ì—ì„œ ìì²´ ìˆ˜í–‰ ëŠ¥ë ¥ì„ í‰ê°€í•˜ë„ë¡ ì§„í–‰ âˆ™ë‹¤ì„¯ ê°€ì§€ ì„ íƒì§€(ë§¤ìš° ë‚®ìŒ, ë‚®ìŒ, ë³´í†µ, ë†’ìŒ, ë§¤ìš° ë†’ìŒ)ë¡œ í‰ê°€ ê²°ê³¼, ì¸ë””ë“œê°€ í‰ê°€ ëŒ€ìƒìœ¼ë¡œ ì‚¼ì€ 2,800ê°œ ì´ìƒì˜ ì§ë¬´ ê¸°ìˆ  ì¤‘ 68.7%ëŠ” ìƒì„±AIë¡œ ëŒ€ì²´ë  ê°€ëŠ¥ì„±ì´ â€œë§¤ìš° ë‚®ìŒâ€ ë˜ëŠ” â€œë‚®ìŒâ€ìœ¼ë¡œ í‰ê°€ëìœ¼ë©°, â€œë§¤ìš° ë†’ìŒâ€ìœ¼ë¡œ í‰ê°€ëœ ê¸°ìˆ ì€ ì „ë¬´nìƒì„±AIëŠ” ì§ë¬´ ê¸°ìˆ ì˜ ì´ë¡ ì  ì§€ì‹ì„ ì œê³µí•˜ëŠ” ìì²´ ëŠ¥ë ¥ì„ ë‹¤ì†Œ ë†’ê²Œ í‰ê°€í–ˆìœ¼ë‚˜, ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ ë° ë¬¼ë¦¬ì  ì‘ì—…ì˜ ì¤‘ìš”ì„±ì— ê´€í•œ íŒë‹¨ ëŠ¥ë ¥ì€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ê²Œ í‰ê°€âˆ™ìƒì„±AIëŠ” ì§ë¬´ ê¸°ìˆ  ì¤‘ 79.7%ì— ì´ë¡ ì  ì§€ì‹ì˜ ì œê³µ ëŠ¥ë ¥ì„ 4ì (ë†’ìŒ)ìœ¼ë¡œ, ê¸°ìˆ  ì¤‘ 70.7%ì— ë¬¸ì œ í•´ê²° ì—­ëŸ‰ì„ 3ì (ë³´í†µ)ìœ¼ë¡œ í‰ê°€í–ˆìœ¼ë©°, ê¸°ìˆ  ì¤‘ 54%ì— ëŒ€í•˜ì—¬ ë¬¼ë¦¬ì  ì‘ì—…ì˜ í•„ìš”ì„±ì´ â€œë†’ìŒâ€ ë˜ëŠ” â€œë§¤ìš° ë†’ìŒâ€ì´ë¼ê³  í‰ê°€** ë§¤ìš° ë‚®ìŒ(very unlikely 1ì ), ë‚®ìŒ(unlikely, 2ì ), ë³´í†µ(possible, 3ì ), ë†’ìŒ(likely, 4ì ), ë§¤ìš° ë†’ìŒ(very likely, 5ì ) âˆ™ìƒì„±AIëŠ” ë¬¼ë¦¬ì  ì‘ì—…ì„ ìˆ˜í–‰í•  ëª¸ì²´ê°€ ì—†ì–´ ì‹¤ì œ ì‘ì—… ìˆ˜í–‰ì´ í•„ìš”í•œ ì§ë¬´ ê¸°ìˆ ì—ì„œëŠ” ì¸ê°„ ê·¼ë¡œìë¥¼ ëŒ€ì²´í•  ê°€ëŠ¥ì„±ì´ ì œí•œì âˆ™ì¼ë¡€ë¡œ ìƒì„±AIëŠ” ë””ì§€í„¸ ê¸°ìˆ  ë¹„ì¤‘ì´ í° ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì§ì¢…ì˜ êµ¬ì¸ ê³µê³ ì—ì„œ í†µìƒ ì œì‹œë˜ëŠ” ì§ë¬´ ê¸°ìˆ ì˜ 71%ì— ëŒ€í•˜ì—¬ ì¸ê°„ì„ ëŒ€ì²´í•  ê°€ëŠ¥ì„±ì´ â€œë³´í†µâ€ ë˜ëŠ” â€œë†’ìŒâ€ìœ¼ë¡œ í‰ê°€í–ˆìœ¼ë‚˜, ê°„í˜¸ì‚¬ ì§ì¢…ì˜ êµ¬ì¸ ê³µê³ ì— ì œì‹œë˜ëŠ” ê¸°ìˆ ì˜ ì•½ 32.9%ë§Œ ìƒì„±AIë¡œ ëŒ€ì²´ë  ê°€ëŠ¥ì„±ì´ â€œë³´í†µâ€ ë˜ëŠ” â€œë†’ìŒâ€ìœ¼ë¡œ í‰ê°€  nì¸ë””ë“œëŠ” í˜„ì¬ ìƒì„±AIì˜ ìµœëŒ€ ê°•ì ì€ ì§ë¬´ ê¸°ìˆ ê³¼ ê´€ë ¨ëœ ì´ë¡ ì  ì§€ì‹ì„ ì œê³µí•˜ëŠ” ëŠ¥ë ¥ì´ë¼ê³  ê°•ì¡°âˆ™ìƒì„±AIëŠ” ì§ì› ìƒì‚°ì„±ì„ ê·¹ëŒ€í™”í•˜ì—¬ ë…¸ë™ ì‹œì¥ì˜ ê²½ìƒ‰ì„ ì™„í™”í•  ìˆ˜ ìˆìœ¼ë©°, ë¬¼ë¦¬ì  ì‘ì—… ìˆ˜í–‰ì´ í•„ìš”í•œ ì§ì—…ì—ì„œë„ ê·¼ë¡œìê°€ í•µì‹¬ ì—…ë¬´ì— ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ ì§€ì› ê°€ëŠ¥  âˆ™ê·¸ëŸ¬ë‚˜ ìƒì„±AIëŠ” ë…¼ë¦¬ì  ì˜¤ë¥˜ë‚˜ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ë‚´ìš© ë˜ëŠ” í¸í–¥ì´ë‚˜ ì°¨ë³„ê³¼ ê°™ì€ ë¹„ìœ¤ë¦¬ì  ì‘ë‹µì„ ì¶œë ¥í•  ê°€ëŠ¥ì„±ë„ ìˆìœ¼ë¯€ë¡œ ì¸ê°„ì˜ ì‹ ì¤‘í•œ ê²€í†  í•„ìš”â˜  ì¶œì²˜: Indeed Hiring Lab, AI at Work: Why GenAI Is More Likely To Support Workers Than Replace Them, 2024.09.25.\n"
     ]
    }
   ],
   "source": [
    "print(docs[22].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "\n",
    "loader = UnstructuredPowerPointLoader('./data/RAG(ì§€ì‹ ê²€ìƒ‰ ë° ìƒì„± ê¸°ë²•)ê¸°ë²• ì ìš©_2ì¼ì°¨.pptx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/RAG(ì§€ì‹ ê²€ìƒ‰ ë° ìƒì„± ê¸°ë²•)ê¸°ë²• ì ìš©_2ì¼ì°¨.pptx'}, page_content='RAG(ì§€ì‹ ê²€ìƒ‰ ë° ìƒì„± ê¸°ë²•) ì ìš©\\n\\nDay 02\\n\\nê°•ì˜ì : ê¹€ìˆ˜ë¹ˆ\\n\\n\\n\\n1\\n\\n2\\n\\n3\\n\\nContents\\n\\nRAG\\n\\në²¡í„° DB\\n\\nLangchain\\n\\n\\n\\n1\\n\\n2\\n\\n3\\n\\n3\\n\\nLangChain\\n\\në­ì²´ì¸?\\n\\n- ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” í”„ë ˆì„ì›Œí¬\\n\\nLLMê³¼ ë„êµ¬ ì—°ê²° : Vecor DB, API, íŒŒì¼ ë“±ê³¼ í†µí•©\\n\\nì‘ì—… ìë™í™” : ìë™í™”ëœ ì›Œí¬í”Œë¡œìš° êµ¬í˜„ ì§€ì›\\n\\nê²€ìƒ‰ ë° ìƒì„± ê¸°ëŠ¥ : LLMê³¼ ê²€ìƒ‰ ê¸°ë°˜ ì‹œìŠ¤í…œì„ ê²°í•©í•´ ì‘ë‹µì˜ í’ˆì§ˆ í–¥ìƒ\\n\\n\\n\\n3\\n\\nLangChain\\n\\nê¸°ëŠ¥\\n\\ní”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­, ì†Œìˆ˜ì˜ ì˜ˆì‹œ, ì‘ë‹µì— ê·¼ê±°í•œ ë‚´ìš© ë“±ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë¬¸ë§¥ ì†ŒìŠ¤ì™€ ëª¨ë¸ì˜ ì—°ê²°\\n\\nâ†’ ì–¸ì–´ ëª¨ë¸ì€ ì œê³µëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.\\n\\në¬¸ë§¥ ì¸ì‹\\n\\nì–¸ì–´ ëª¨ë¸ì€ ì£¼ì–´ì§„ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì–´ë–¤ ë‹µë³€ì„ ì œê³µí•˜ê±°ë‚˜ ì–´ë–¤ ì¡°ì·¨ë¥¼ ì·¨í•´ì•¼ í• ì§€ ìŠ¤ìŠ¤ë¡œ ì¶”ë¡ í•  ìˆ˜ ìˆë‹¤\\n\\nâ†’ ë‹¨ìˆœíˆ ì •ë³´ ì¬ìƒì‚°ì´ ì•„ë‹ˆë¼ ì£¼ì–´ì§„ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ í•´ê²°ì±… ì œì‹œ ê°€ëŠ¥\\n\\nì¶”ë¡ \\n\\n\\n\\n3\\n\\nLangChain\\n\\nLangSmith\\n\\nLLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ, ëª¨ë‹ˆí„°ë§ ë° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í”Œë«í¼\\n\\në‹¨ìˆœíˆ ì •ë³´ ì¬ìƒì‚°ì´ ì•„ë‹ˆë¼ ì£¼ì–´ì§„ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ í•´ê²°ì±… ì œì‹œ ê°€ëŠ¥\\n\\nì¶”ì  ê¸°ëŠ¥\\n\\nì˜ˆìƒì¹˜ ëª»í•œ ìµœì¢… ê²°ê³¼, ì²´ì¸ì´ ì˜ˆìƒë³´ë‹¤ ëŠë¦° ì´ìœ  ë“±ì— ëŒ€í•´ ì¶”ì í•˜ëŠ”ë° ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤\\n\\n\\n\\n3\\n\\nLangChain\\n\\nLangSmith\\n\\nhttps://smith.langchain.com\\n\\n- ë§ˆì°¬ê°€ì§€ë¡œ í‚¤ ë°œê¸‰(â˜…â˜…â˜…â˜…â˜…â˜…ì €ì¥í•„ìˆ˜)\\n\\n- .envì— ë„£ì–´ì•¼ í•  í•­ëª©\\n\\n```\\n\\nLANGCHAIN_TRACING_V2 = true\\n\\nLANGCHAIN_ENDPOINT = https://api.langchain.com\\n\\nLANGCHAIN_API_KEY = ë°œê¸‰ë°›ì€ í‚¤\\n\\nLANGCHAIN_PROJECT = í”„ë¡œì íŠ¸ëª…\\n\\n```\\n\\n\\n\\nê°ì‚¬í•©ë‹ˆë‹¤.\\n\\nThank You')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://blog.langchain.dev/'\n",
    "url2 = 'https://blog.langchain.dev/langgraph-v0-2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_path=(url1, url2),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only = bs4.SoupStrainer(\n",
    "            class_ = ('article-content', 'article-header')\n",
    "        )\n",
    "    )\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nToday, weâ€™re excited to announce the stable release of LangGraph v0.2, which introduces a new ecosystem of LangGraph checkpointer libraries. These simplify the creation and customization of checkpointers, which allows users to build more resilient LLM applications with smooth session memory, robust error recovery, and human-in-the-loop features.Why we built LangGraph v0.2One of the key pillars of LangGraph is its built-in persistence layer, implemented through checkpointers. When you use a checkpointer with a graph, you can interact with and manage the graph's state. The checkpointer saves a checkpoint of the graph state at each step, enabling several powerful capabilities, including:Session memory: Store history (checkpoints) of user interactions and resume from a saved checkpoint in follow up interactionsError recovery: Recover from failures at any given step in the graph execution by continuing from the last successful step checkpointHuman-in-the-loop: Implement tool approval, wait for human input, edit agent actions and moreTime travel: Edit graph state at any point in the history of execution and create an alternative execution from that point in time (i.e. fork the thread)Since the early days of LangGraph, weâ€™ve designed checkpointing to be database-agnostic, allowing users to implement their own checkpointer adapters for their database of choice.Since the LangGraph v0.1 release, we've seen a lot of interest from the community in creating checkpointers for many popular databases like Postgres, Redis, and MongoDB. However, there was no clear blueprint for the users to implement their own, custom checkpointers.New checkpointer libraries in LangGraphWith LangGraph v0.2, weâ€™re making it easier to create new checkpointers. Weâ€™ve also laid the foundation to foster a community-maintained ecosystem of checkpointer implementations.We now have a suite of new, dedicated checkpointer libraries:langgraph_checkpoint : The base interface for checkpointer savers (BaseCheckpointSaver ) and serialization/deserialization interface (SerializationProtocol). Includes in-memory checkpointer implementation (MemorySaver) for experimentation.langgraph_checkpoint_sqlite : An implementation of LangGraph checkpointer that uses SQLite database. Ideal for experimentation and local workflows.langgraph_checkpoint_postgres : Our advanced checkpointer that we wrote and optimized for Postgres in LangGraph Cloud is now open-sourced and available to the community to build upon. Ideal for using in production.Checkpointer implementations can be used interchangeably, which lets users tailor their stateful LangGraph applications to their custom needs.LangGraph Postgres Checkpointer for production-ready appslanggraph_checkpoint_postgres implementation can serve as a blueprint for community members to implement their own optimized, production-ready checkpointers for their favorite database. Postgres checkpointer implements a number of optimizations both on the write-, as well as read-side.Write-side optimizations:We're making use of Postgres pipeline mode to reduce database roundtripsWe're storing each channel value separately and versioned so that each new checkpoint only stores the values that changed.Read-side optimizations:We're making use of a cursor for the list endpoint in order to efficiently fetch long thread histories when needed.Getting started on LangGraph v0.2Since LangGraph checkpointer libraries are implemented as namespace packages, you can import checkpointer interfaces and implementations the same way as before, using:from langgraph.checkpoint.base import BaseCheckpointSaverfrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.checkpoint.sqlite import SqliteSaverfrom langgraph.checkpoint.postgres import PostgresSaverSince SQLite and Postgres checkpointers are provided via separate libraries, you will need to install them using pip install langgraph-checkpoint-sqlite or pip install langgraph-checkpoint-postgres.LangGraph checkpoint libraries will follow semantic versioning (starting with current release of 1.0), and any breaking changes in the main library will result in a major version bump for those libraries. For example, the next breaking change in langgraph_checkpoint will result in 2.0 version, and you can expect the checkpointer implementations (e.g.,langgraph_checkpoint_sqlite) to also be updated to 2.0 to follow that change.To get started, follow this guide on how to use checkpointers in LangGraph. You can also check out our documentation, including a reference and overview of checkpointers. Run agents at scale with LangGraph CloudTo complement the LangGraph framework, we also have a new runtime, LangGraph Cloud, which provides infrastructure purpose-built for deploying agents at scale.LangGraph Cloud does the heavy lifting for your agentic application, removing the maintenance work for custom checkpointers while adding fault-tolerant scalability. It gracefully manages horizontally-scaling task queues, servers, and includes our robust Postgres checkpointer out-of-the-box to help you handle many concurrent users and efficiently store large states and threads.In addition, LangGraph Cloud supports real-world interaction patterns beyond streaming and human-in-the-loop. These include double-texting to handle new user inputs on currently-running threads of the graph, async background jobs for long-running tasks, and cron jobs.Lastly, you can easily deploy your agentic app and collaborate in LangGraph Studio, a playground-like space for visualizing and debugging agent trajectories, with LangGraph Cloud. The LangGraph Studio desktop app is now also available for all LangSmith users to try for free.LangGraph Cloud is now available in beta for all LangSmith users on Plus or Enterprise plans. Try it out today for free by signing up for LangSmith.Additional changes in LangGraph v0.2LangGraph v0.2 contains many improvements, and we've designed it to be largely backwards compatible. Below is a list of breaking changes and deprecations in this latest version.Breaking changesLangGraph v0.2 introduces several breaking changes:thread_ts and parent_ts have been renamed to checkpoint_id and parent_checkpoint_id , respectively (via langgraph_checkpoint==1.0.0).Note: LangGraph checkpointers still recognize thread_ts if passed via config and treat it as checkpoint_idRe-exported imports like from langgraph.checkpoint import BaseCheckpointSaver are no longer possible due to the use of namespace packages. Instead, use from langgraph.checkpoint.base import BaseCheckpointSaverSQLite checkpointers have been moved to a separate library, so youâ€™ll need to install them separately using pip install langgraph-checkpoint-sqliteDeprecationsIn LangGraph v0.2, we've removed:langgraph.prebuilt.chat_agent_executor.create_function_calling_executor . We recommend you use langgraph.prebuilt.chat_agent_executor.create_react_agent instead.langgraph.prebuilt.agent_executor . We recommend you use langgraph.prebuilt.chat_agent_executor.create_react_agent instead.ConclusionWe are incredibly grateful to our community and users for pushing us and building with LangGraph to improve agent reliability. We hope that with LangGraph v0.2, youâ€™ll find it easier to build and maintain your own checkpointer implementationsâ€“ and weâ€™re excited to see all the apps that you create.As you try out LangGraph v0.2, we'd love to hear your feedback at hello@langchain.dev. You can also learn more from these additional resources:LangGraph docsLangGraph webpage (with FAQs)\\n\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ArxivLoader(\n",
    "    query = 'ChatGPT',\n",
    "    load_max_docs = 2,\n",
    "    load_all_available_meta = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2023-10-05',\n",
       " 'Title': 'In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT',\n",
       " 'Authors': 'Xinyue Shen, Zeyuan Chen, Michael Backes, Yang Zhang',\n",
       " 'Summary': \"The way users acquire information is undergoing a paradigm shift with the\\nadvent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves\\nknowledge from the model itself and generates answers for users. ChatGPT's\\nimpressive question-answering (QA) capability has attracted more than 100\\nmillion users within a short period of time but has also raised concerns\\nregarding its reliability. In this paper, we perform the first large-scale\\nmeasurement of ChatGPT's reliability in the generic QA scenario with a\\ncarefully curated set of 5,695 questions across ten datasets and eight domains.\\nWe find that ChatGPT's reliability varies across different domains, especially\\nunderperforming in law and science questions. We also demonstrate that system\\nroles, originally designed by OpenAI to allow users to steer ChatGPT's\\nbehavior, can impact ChatGPT's reliability in an imperceptible way. We further\\nshow that ChatGPT is vulnerable to adversarial examples, and even a single\\ncharacter change can negatively affect its reliability in certain cases. We\\nbelieve that our study provides valuable insights into ChatGPT's reliability\\nand underscores the need for strengthening the reliability and security of\\nlarge language models (LLMs).\"}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2023-12-30',\n",
       " 'Title': 'Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect ChatGPT-Generated Text',\n",
       " 'Authors': 'Lingyi Yang, Feng Jiang, Haizhou Li',\n",
       " 'Summary': 'The remarkable capabilities of large-scale language models, such as ChatGPT,\\nin text generation have impressed readers and spurred researchers to devise\\ndetectors to mitigate potential risks, including misinformation, phishing, and\\nacademic dishonesty. Despite this, most previous studies have been\\npredominantly geared towards creating detectors that differentiate between\\npurely ChatGPT-generated texts and human-authored texts. This approach,\\nhowever, fails to work on discerning texts generated through human-machine\\ncollaboration, such as ChatGPT-polished texts. Addressing this gap, we\\nintroduce a novel dataset termed HPPT (ChatGPT-polished academic abstracts),\\nfacilitating the construction of more robust detectors. It diverges from extant\\ncorpora by comprising pairs of human-written and ChatGPT-polished abstracts\\ninstead of purely ChatGPT-generated texts. Additionally, we propose the \"Polish\\nRatio\" method, an innovative measure of the degree of modification made by\\nChatGPT compared to the original human-written text. It provides a mechanism to\\nmeasure the degree of ChatGPT influence in the resulting text. Our experimental\\nresults show our proposed model has better robustness on the HPPT dataset and\\ntwo existing datasets (HC3 and CDB). Furthermore, the \"Polish Ratio\" we\\nproposed offers a more comprehensive explanation by quantifying the degree of\\nChatGPT involvement.'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The way users acquire information is undergoing a paradigm shift with the\n",
      "advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves\n",
      "knowledge from the model itself and generates answers for users. ChatGPT's\n",
      "impressive question-answering (QA) capability has attracted more than 100\n",
      "million users within a short period of time but has also raised concerns\n",
      "regarding its reliability. In this paper, we perform the first large-scale\n",
      "measurement of ChatGPT's reliability in the generic QA scenario with a\n",
      "carefully curated set of 5,695 questions across ten datasets and eight domains.\n",
      "We find that ChatGPT's reliability varies across different domains, especially\n",
      "underperforming in law and science questions. We also demonstrate that system\n",
      "roles, originally designed by OpenAI to allow users to steer ChatGPT's\n",
      "behavior, can impact ChatGPT's reliability in an imperceptible way. We further\n",
      "show that ChatGPT is vulnerable to adversarial examples, and even a single\n",
      "character change can negatively affect its reliability in certain cases. We\n",
      "believe that our study provides valuable insights into ChatGPT's reliability\n",
      "and underscores the need for strengthening the reliability and security of\n",
      "large language models (LLMs).\n"
     ]
    }
   ],
   "source": [
    "docs = loader.get_summaries_as_docs()\n",
    "print(docs[0].page_content)  # 0ë²ˆì§¸ ë¬¸ì„œì˜ ìš”ì•½ì„ ë³¼ ìˆ˜ ìˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
